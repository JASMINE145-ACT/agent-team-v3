# 上下文工程借鉴 — 供思考

基于 [Agent-Skills-for-Context-Engineering](https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering) 与 Agent Team version3 的对照，整理「可借鉴点」与待决问题，便于后续选方向、做改进。

---

## 1. context-compression / context-optimization

| 项目 | 内容 |
|------|------|
| **version3 现状** | `_trim_context` 超 _CONTEXT_MAX_CHARS 时把历史 tool 结果压成「已压缩，原长 N 字符」；TOOL_RESULT_MAX_CHARS=8k；INJECT_TURNS=2、INJECT_ANSWER_TRIM=500。 |
| **可借鉴点** | **结构化压缩**：用摘要替代长文，而不是直接截断或整段替换。对历史 tool 结果做 summarization（例如每步 observation 保留「结论句 + 关键字段」），再拼进 context。可参考 compaction、masking、caching 的套路，进一步控 token、缓解「几句对话就 3 万 token」。 |
| **待思考** | 是否引入「每步 tool 结果写一个简短 summary」再入 context？由谁生成 summary（规则抽取 vs 小模型/LLM）？压缩后如何保证选型/报价等关键信息不丢？ |

### 方案细节（若真做）

- **目标**：历史 tool 结果不再整段替换为「已压缩，原长 N 字符」，改为用**短摘要**（约 400～800 字）保留「结论 + 关键字段」，既省 token 又保留选型/报价等关键信息。
- **谁生成 summary**：**用轻量 LLM** 生成摘要。可选：同一智谱/OpenAI 的**小模型**（如 glm-4-flash、gpt-4o-mini）、或本地小模型（如 Qwen2-0.5B/1.5B、Phi-3 mini、Llama 3.2 3B 等），单次输入为「工具名 + 原始 observation 文本」，输出为一句话摘要，token 少、延迟低。若希望零额外调用成本，可保留「规则 fallback」：LLM 超时/失败时退回规则截断（见下）。
- **何时调用 LLM**：在 **`_trim_context` 执行时**，对需要被压缩的每条 tool 消息调用一次摘要（传入 `tool_name` + `content`）。注意：trim 发生在 ReAct 循环内、下一轮 LLM 主调用之前，若摘要模型较慢可考虑：(1) 设短超时（如 3s），超时则用规则 fallback；(2) 或改为「工具执行完立即异步调摘要、结果存起来，trim 时直接用」——需在 message 或旁路结构里存 summary，实现稍复杂。
- **Prompt 要点**：system 或 user 里明确「请用 1～3 句话概括该工具返回结果，必须保留：选中的 code/名称、价格/档位、库存数等对后续决策有用的信息；不要保留表格原文，只保留结论和关键数字」。输入 = 工具名 + **完整** content（与 TOOL_RESULT_MAX_CHARS 一致，上限 8000 字），整段喂给摘要模型，生成 800 字以内摘要，避免只摘前 2000 字丢信息。
- **规则 fallback**（LLM 未配/超时/失败时）：按工具类型做简单抽取，例如 match 类抽「选中、code、价格」相关行，库存类抽「找到 N 条」+ 前几条 code，其它取首 2 行 + 含关键词的行，总长 cap 在 800 字内。保证任何情况下都不会把整段替换成「已压缩，原长 N 字符」而丢掉全部信息。
- **如何拿到 tool_name**：`messages` 里 tool 消息只有 `tool_call_id`。在 `_trim_context` 里先扫一遍 messages，从 `role=="assistant"` 且带 `tool_calls` 的项里建 `tool_call_id -> function.name` 的映射；处理每条 `role=="tool"` 时用该映射取 `tool_name` 传入摘要函数。
- **与现有逻辑的关系**：`TOOL_RESULT_MAX_CHARS`、`_CONTEXT_MAX_CHARS` 不变；`_trim_context` 的「超限则压缩」逻辑不变，仅把「压缩后的内容」从固定文案改为「LLM 摘要（或规则 fallback）」的返回值。trace 里仍保留完整 observation，不影响排查。

---

## 2. context-degradation

| 项目 | 内容 |
|------|------|
| **version3 现状** | 「当前意图」绑定上一轮（短回复时显式写「用户本句是对上一轮问：xxx 的回复」）；build_injection 末尾有「请以最近一轮的问为主题理解」；最近 2 轮注入。 |
| **可借鉴点** | **lost-in-the-middle、U 型注意力**：模型对 context 中间段关注度容易下降。用来检查：重要信息（当前产品名、用户意图、当前档位/客户级别）是否放在**模型更容易注意到的位置**（例如 user 消息末尾、system 末尾），而不是埋在长段历史中间。 |
| **待思考** | 当前「当前意图」和「最近一轮」说明是否已经足够靠后？是否需要把「本对话当前主题」（如「外螺纹堵头 / 价格」）单独提一句放在每条 user 消息的最前面或最后面？ |

### 方案细节（若真做）

- **目标**：把「本对话当前主题」（上一轮问的是什么 + 用户本句在说什么）放在 **user 消息的绝对末尾**，吃准 U 型注意力里「末尾高权重」，减少被中间长段干扰。
- **放哪里**：**每条 user 消息的最后一句话**（即 `user_content` 拼完 session injection 之后，再追加一行）。不放在 system 末尾，因为 system 是启动时固定的，每轮变化的上下文只适合放在 user 里。
- **具体文案**：当存在 `session_id` 且 `session.turns` 非空时，在 `user_content` 末尾追加一行（且只保留这一行在最后）：  
  `【当前主题】上一轮问：{last_turn.query 前 80 字}。用户本句：{user_input 前 50 字}。请据此理解意图与所指产品。`  
  这样无论用户发的是长句还是短句「价格」，模型最后一眼看到的都是「上一轮问的是什么 + 本句是什么」，便于绑定到正确产品。
- **与现有逻辑的关系**：保留现有「短回复时加【当前意图】」和 `build_injection` 末尾的「请以最近一轮的问为主题理解」。新增的只是：在 **injection 之后** 再加这一句「【当前主题】…」，作为 user 消息的**最后一行**，形成「历史轮次 → 说明 → 当前主题」的顺序，把「当前主题」压到注意力最优位置。
- **实现位置**：`backend/core/agent.py` 里拼 `user_content` 的流程末尾（在 `user_content += f"\n\n{injection}"` 之后），若 `session_id and self._store` 且 `session.turns` 非空，则：  
  `user_content += "\n\n【当前主题】上一轮问：{...}。用户本句：{...}。请据此理解意图与所指产品。"`  
  无需改 `session.py`，无需新字段。
- **可选增强**：若后续有「当前档位」「当前 file_path」等，可在同一句里补上，例如「当前主题：…；当前档位：B；已上传文件：xxx」。仍保持单行、在 user 消息最后。

---

## 3. tool-design

| 项目 | 内容 |
|------|------|
| **version3 现状** | 技能在 `skills.py`，工具 description 已收紧（只写「做什么」），决策以 system prompt 为准；ToolRegistry 查表分发。 |
| **可借鉴点** | 再减 tool 描述复杂度、减少误用与多轮无效调用；MCP/工具设计原则（命名、参数粒度、返回结构），便于后续加工具或改 prompt。 |
| **待思考** | 哪些工具最常被误用或重复调用？能否用「工具使用契约」（何时必须调、何时禁止调）写进 skill 或 description？新工具上线前要不要有「最小描述 + 示例」的 checklist？ |

---

## 4. memory-systems

| 项目 | 内容 |
|------|------|
| **version3 现状** | SessionStore = 最近 N 轮 JSON（turns），无长期记忆；无会话摘要、无实体/产品上下文单独存储。 |
| **可借鉴点** | 短期/长期/图记忆的划分；是否需要「会话摘要」或「实体/产品上下文」的单独存储，而不是只拼原始 turn 文本。例如：当前会话涉及的产品列表、最近一次选型结果、当前 file_path，单独维护一份「会话级上下文」再注入，可减少重复工具调用、减少长段历史。 |
| **待思考** | 是否要为「当前会话」维护一个轻量级上下文结构（如：current_product_keywords、last_chosen_code、current_file_path）？由谁写入（工具回调 vs agent 输出解析）？和现有 session.turns 如何分工？ |

---

## 5. evaluation / advanced-evaluation

| 项目 | 内容 |
|------|------|
| **version3 现状** | 没有成体系的评估；改 prompt/改上下文策略后主要靠人工试几条对话判断。 |
| **可借鉴点** | 若要做「改 prompt/改上下文策略是否更好」，可借鉴其评估框架与 LLM-as-judge 思路：回归用例（固定 query 集）、质量维度（是否答对、是否少调工具、是否无幻觉）、可选 LLM 打分或 pairwise 比较。 |
| **待思考** | 是否愿意投入「少量标准 query + 期望行为」做成回归集？评估是只做人工抽检，还是希望自动化（脚本 + 可选 LLM judge）？ |

---

## 小结（可选优先级）

1. **优先**：context-compression/optimization（摘要替代截断）、context-degradation（重要信息位置检查）— 直接缓解 token 与理解偏差。  
2. **其次**：tool-design 收敛（减少误用）、memory-systems 里「会话级上下文」是否落地。  
3. **按需**：evaluation 是否建一套最小回归集与评估方式。

文档位置：`Agent Team version3/doc/上下文工程借鉴-供思考.md`。后续若在某一块有结论或改动，可在此文件对应小节补「结论/已做」即可。
