"""
Streamlit ä¸»åº”ç”¨
"""
import inspect
import streamlit as st
import pandas as pd
import logging
import tempfile
from datetime import datetime
import sys
from pathlib import Path

# éœ€ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼Œå¦‚ï¼špython -m streamlit run backend/tools/oos/app.py
from backend.tools.oos.processor import QuotationProcessor
from backend.tools.oos.models import ProcessingResult
from backend.tools.oos.services.agent_runner import run_quotation_agent

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æŠ¥ä»·å•æ— è´§äº§å“è¿½è¸ªç³»ç»Ÿ",
    page_icon="ğŸ“¦",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ– Session State
if "processing_results" not in st.session_state:
    st.session_state.processing_results = {}

# åˆå§‹åŒ–å¤„ç†å™¨
@st.cache_resource
def get_processor():
    """ç¼“å­˜å¤„ç†å™¨å®ä¾‹"""
    return QuotationProcessor()

processor = get_processor()

# ä¸»é¡µé¢
st.title("ğŸ“¦ æŠ¥ä»·å•æ— è´§äº§å“è¿½è¸ªç³»ç»Ÿ")
st.markdown("---")

# ä¾§è¾¹æ ï¼šå¯¼èˆª
st.sidebar.title("å¯¼èˆª")
page = st.sidebar.selectbox(
    "é€‰æ‹©é¡µé¢",
    ["ä¸Šä¼ æ–‡ä»¶", "æŒ‰æ–‡ä»¶æŸ¥çœ‹", "æ— è´§äº§å“åˆ—è¡¨", "ç»Ÿè®¡ä¿¡æ¯"]
)

# æ–‡ä»¶ä¸Šä¼ é¡µé¢
if page == "ä¸Šä¼ æ–‡ä»¶":
    st.subheader("ä¸Šä¼  Excel æŠ¥ä»·å•")
    
    analysis_mode = st.radio(
        "åˆ†ææ–¹å¼",
        ["ç®¡é“ï¼ˆåŸï¼šæ•°æ®æ®µ + LLM ç»“æ„åŒ–æå–ï¼‰", "Agentï¼ˆæŒ‰æ ¼è§£ææ— è´§ï¼Œæ€è€ƒ + å·¥å…·ï¼‰"],
        horizontal=True,
        help="Agent æ–¹å¼ä¸ opencode_style_agent ä¸€è‡´ï¼šæŒ‰å•å…ƒæ ¼æ‰«æ— è´§ã€å¯å…œåº•æ™ºè°±ä¸èµ° tool_calls",
    )
    use_agent = "Agent" in analysis_mode

    uploaded_file = st.file_uploader(
        "é€‰æ‹©æ–‡ä»¶",
        type=["xlsx", "xls"],
        help="æ”¯æŒ .xlsx å’Œ .xls æ ¼å¼"
    )
    
    if uploaded_file is not None:
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        with col1:
            st.info(f"ğŸ“„ æ–‡ä»¶åï¼š{uploaded_file.name}")
        with col2:
            file_size_mb = uploaded_file.size / (1024 * 1024)
            st.info(f"ğŸ“Š æ–‡ä»¶å¤§å°ï¼š{file_size_mb:.2f} MB")
        with col3:
            st.info(f"ğŸ• ä¸Šä¼ æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        agent_question = ""
        if use_agent:
            agent_question = st.text_input(
                "å‘ Agent æé—®",
                value="æŠ“å–è¿™ä»½æŠ¥ä»·å•çš„æ— è´§æ•°æ®ï¼Œä½ è§‚å¯Ÿåå†³å®šå“ªäº›è¦å­˜åº“ï¼ŒæŠŠé€‰ä¸­çš„æŒä¹…åŒ–åˆ°æ•°æ®åº“ã€‚",
                key="agent_question",
            )
        
        if st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary", width="stretch"):
            with st.spinner("â³ æ­£åœ¨å¤„ç†ï¼Œè¯·ç¨å€™..."):
                try:
                    file_bytes = uploaded_file.read()

                    if use_agent:
                        # Agent æ–¹å¼ï¼šè½ç›˜åˆ°ä¸´æ—¶è·¯å¾„åè·‘ run_quotation_agentï¼ˆå‰ç«¯åªä¼ æ–‡ä»¶ï¼‰
                        with tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False) as tmp:
                            tmp.write(file_bytes)
                            tmp_path = tmp.name
                        try:
                            default_q = "æŠ“å–è¿™ä»½æŠ¥ä»·å•çš„æ— è´§æ•°æ®ï¼Œä½ è§‚å¯Ÿåå†³å®šå“ªäº›è¦å­˜åº“ï¼ŒæŠŠé€‰ä¸­çš„æŒä¹…åŒ–åˆ°æ•°æ®åº“ã€‚"
                            kwargs = {"file_path": tmp_path, "question": agent_question or default_q}
                            if "file_name" in inspect.signature(run_quotation_agent).parameters:
                                kwargs["file_name"] = uploaded_file.name
                            out = run_quotation_agent(**kwargs)
                            if out.get("error"):
                                st.error(f"âŒ {out['error']}")
                            else:
                                if out.get("thinking"):
                                    with st.expander("ğŸ” æ€è€ƒè¿‡ç¨‹", expanded=False):
                                        st.text(out["thinking"])
                                st.success("âœ… Agent åˆ†æå®Œæˆ")
                                st.markdown("**å›ç­”**")
                                st.write(out.get("answer") or "(æ— å›å¤)")
                        finally:
                            Path(tmp_path).unlink(missing_ok=True)
                        # Agent æ¨¡å¼ä¸å†™ processing_results / ä¸å±•ç¤ºç®¡é“è¡¨æ ¼
                    else:
                        # åŸç®¡é“å¤„ç†
                        result = processor.process_file(
                            file_bytes=file_bytes,
                            filename=uploaded_file.name
                        )
                        
                        file_key = f"{uploaded_file.name}_{uploaded_file.size}"
                        st.session_state.processing_results[file_key] = result
                        
                        if result.success:
                            st.success(f"âœ… æˆåŠŸå¤„ç†ï¼æ‰¾åˆ° {result.out_of_stock_count} ä¸ªæ— è´§äº§å“")

                            debug_sheets = getattr(result, "debug_per_sheet", None)
                            if debug_sheets:
                                with st.expander("ğŸ” è°ƒè¯•ä¿¡æ¯ï¼ˆæ¯ Sheet æ•°æ®æ®µä¸ LLM ç»“æœï¼‰"):
                                    for d in debug_sheets:
                                        err = f" â€” {d['error']}" if d.get("error") else ""
                                        st.text(
                                            f"Sheetã€Œ{d['sheet']}ã€: å…¨è¡¨ {d['total_rows']} è¡Œ â†’ é€ LLM {d['data_section_rows']} è¡Œ | "
                                            f"å†…å®¹å«ã€Œæ— è´§ã€: {'æ˜¯' if d.get('has_wu_huo') else 'å¦'} | LLM æå–: {d.get('llm_count', 0)} æ¡{err}"
                                        )
                                    if result.out_of_stock_count == 0 and debug_sheets:
                                        st.caption(
                                            "è‹¥ã€Œå†…å®¹å«æ— è´§: å¦ã€è¯´æ˜æ•°æ®æ®µå¯èƒ½è¢«æˆªå¾—è¿‡æ—©ï¼Œå¯è°ƒå¤§ MAX_TABLE_ROWS_FOR_LLM æˆ–æ£€æŸ¥è¡¨å°¾å…³é”®è¯ï¼›"
                                            "è‹¥ã€Œæ˜¯ã€ä½† LLM æå– 0 æ¡ï¼Œå¤šä¸ºæ¨¡å‹æœªè¯†åˆ«ï¼Œå¯å°è¯•è°ƒæ•´ prompt æˆ–æ¢æ¨¡å‹ã€‚"
                                        )
                            
                            if result.records:
                                with st.container():
                                    st.subheader("ğŸ“‹ æå–ç»“æœ")
                                    df = pd.DataFrame([{
                                        "äº§å“åç§°": r.product_name,
                                        "è§„æ ¼å‹å·": r.specification or "",
                                        "å•ä½": r.unit,
                                        "æ•°é‡": r.quantity
                                    } for r in result.records])
                                    st.dataframe(
                                        df,
                                        width="stretch",
                                        height=400
                                    )
                            
                            if result.email_triggered:
                                st.warning("âš ï¸ å·²è§¦å‘é‚®ä»¶é€šçŸ¥ï¼ˆç¼ºè´§æ¬¡æ•° â‰¥ 2ï¼‰")
                        else:
                            st.warning(f"âš ï¸ å¤„ç†å®Œæˆï¼Œä½†æœªæ‰¾åˆ°æ— è´§äº§å“" if not result.error else f"âŒ {result.error}")
                        
                except Exception as e:
                    st.error(f"âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}")
                    logger.exception("å¤„ç†æ–‡ä»¶å¼‚å¸¸")

# æŒ‰æ–‡ä»¶æŸ¥çœ‹é¡µé¢
elif page == "æŒ‰æ–‡ä»¶æŸ¥çœ‹":
    st.subheader("ğŸ“‚ æŒ‰æ–‡ä»¶æŸ¥çœ‹æ— è´§è®°å½•")

    try:
        # è·å–æ‰€æœ‰æ–‡ä»¶
        files = processor.data_service.get_files_summary()

        if files:
            st.markdown(f"**å…±æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶**")

            # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
            for idx, file_info in enumerate(files):
                with st.expander(
                    f"ğŸ“„ {file_info['file_name']} "
                    f"ï¼ˆ{file_info['total_records']} æ¡è®°å½•ï¼Œ"
                    f"ä¸Šä¼ æ—¶é—´ï¼š{file_info['uploaded_at'][:19] if file_info['uploaded_at'] else 'æœªçŸ¥'}ï¼‰"
                ):
                    # æŸ¥è¯¢è¯¥æ–‡ä»¶çš„è®°å½•
                    records = processor.data_service.get_records_by_file(
                        file_name=file_info['file_name'],
                        batch_id=file_info['upload_batch_id']
                    )

                    if records:
                        df = pd.DataFrame(records)

                        # æ˜¾ç¤ºæ‘˜è¦ä¿¡æ¯
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("æ— è´§äº§å“æ•°", len(df))
                        with col2:
                            high_count = len(df[df['count'] >= 2])
                            st.metric("é«˜é¢‘æ— è´§ï¼ˆâ‰¥2æ¬¡ï¼‰", high_count)
                        with col3:
                            email_sent = len(df[df['email_status'] == 'sent'])
                            st.metric("å·²å‘é‚®ä»¶", email_sent)

                        # æ˜¾ç¤ºè¯¦ç»†åˆ—è¡¨
                        st.dataframe(
                            df[['product_name', 'specification', 'unit', 'quantity', 'count', 'email_status']],
                            width="stretch",
                            column_config={
                                "product_name": "äº§å“åç§°",
                                "specification": "è§„æ ¼å‹å·",
                                "unit": "å•ä½",
                                "quantity": "æ•°é‡",
                                "count": "æ— è´§æ¬¡æ•°",
                                "email_status": "é‚®ä»¶çŠ¶æ€"
                            }
                        )
                    else:
                        st.info("è¯¥æ–‡ä»¶æ— æœ‰æ•ˆè®°å½•")
        else:
            st.info("æš‚æ— ä¸Šä¼ æ–‡ä»¶")
    except Exception as e:
        st.error(f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}")

# æ— è´§äº§å“åˆ—è¡¨é¡µé¢
elif page == "æ— è´§äº§å“åˆ—è¡¨":
    st.subheader("ğŸ“‹ æ— è´§äº§å“åˆ—è¡¨")

    # æŸ¥è¯¢æ•°æ®
    try:
        records = processor.data_service.get_all_records(limit=1000)

        if records:
            df = pd.DataFrame(records)

            # æ·»åŠ æ“ä½œåˆ—ï¼ˆå¤é€‰æ¡†ï¼‰
            st.markdown("**é€‰æ‹©è¦åˆ é™¤çš„è®°å½•ï¼š**")

            # ä½¿ç”¨ session_state å­˜å‚¨é€‰ä¸­çš„è®°å½•
            if "selected_records" not in st.session_state:
                st.session_state.selected_records = []

            # æ“ä½œæŒ‰é’®
            col1, col2, col3 = st.columns([1, 1, 4])
            with col1:
                if st.button("ğŸ—‘ï¸ åˆ é™¤é€‰ä¸­", type="primary"):
                    if st.session_state.selected_records:
                        # ç¡®è®¤å¯¹è¯æ¡†
                        if "delete_confirmed" not in st.session_state:
                            st.session_state.delete_confirmed = False

                        if not st.session_state.delete_confirmed:
                            st.warning(f"ç¡®å®šè¦åˆ é™¤ {len(st.session_state.selected_records)} æ¡è®°å½•å—ï¼Ÿ")
                            col_yes, col_no = st.columns(2)
                            with col_yes:
                                if st.button("âœ… ç¡®è®¤åˆ é™¤"):
                                    deleted_count = processor.data_service.batch_delete_records(
                                        st.session_state.selected_records
                                    )
                                    st.success(f"âœ… å·²åˆ é™¤ {deleted_count} æ¡è®°å½•")
                                    st.session_state.selected_records = []
                                    st.session_state.delete_confirmed = False
                                    st.rerun()
                            with col_no:
                                if st.button("âŒ å–æ¶ˆ"):
                                    st.session_state.delete_confirmed = False
                                    st.rerun()
                    else:
                        st.warning("âš ï¸ è¯·å…ˆé€‰æ‹©è¦åˆ é™¤çš„è®°å½•")

            with col2:
                if st.button("ğŸ”„ åˆ·æ–°åˆ—è¡¨"):
                    st.session_state.selected_records = []
                    st.rerun()

            # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼ï¼ˆå¸¦é€‰æ‹©åˆ—ï¼‰
            # æ·»åŠ å¤é€‰æ¡†åˆ—
            df_display = df.copy()

            # ä½¿ç”¨ data_editor æ”¯æŒé€‰æ‹©
            edited_df = st.data_editor(
                df_display,
                width="stretch",
                height=500,
                disabled=list(df_display.columns),  # ç¦ç”¨ç¼–è¾‘
                hide_index=False,
                column_config={
                    "id": st.column_config.NumberColumn("ID", width="small"),
                    "product_name": st.column_config.TextColumn("äº§å“åç§°", width="medium"),
                    "specification": st.column_config.TextColumn("è§„æ ¼å‹å·", width="medium"),
                    "count": st.column_config.NumberColumn("æ— è´§æ¬¡æ•°", width="small"),
                    "email_status": st.column_config.TextColumn("é‚®ä»¶çŠ¶æ€", width="small"),
                    "email_sent_by": st.column_config.TextColumn("å‘é€äºº", width="small"),
                }
            )

            # å¤šé€‰åˆ é™¤åŠŸèƒ½ï¼ˆç®€åŒ–ç‰ˆï¼‰
            st.markdown("---")
            st.markdown("**å¿«é€Ÿåˆ é™¤ï¼šè¾“å…¥è¦åˆ é™¤çš„è®°å½• IDï¼ˆç”¨é€—å·åˆ†éš”ï¼‰**")
            delete_ids_input = st.text_input("ä¾‹å¦‚ï¼š1,3,5", key="delete_ids_input")
            if st.button("ğŸ—‘ï¸ æ‰¹é‡åˆ é™¤"):
                if delete_ids_input:
                    try:
                        ids = [int(x.strip()) for x in delete_ids_input.split(",")]
                        deleted_count = processor.data_service.batch_delete_records(ids)
                        st.success(f"âœ… å·²åˆ é™¤ {deleted_count} æ¡è®°å½•")
                        st.rerun()
                    except ValueError:
                        st.error("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„ IDï¼ˆæ•°å­—ï¼Œç”¨é€—å·åˆ†éš”ï¼‰")
        else:
            st.info("æš‚æ— æ•°æ®")
    except Exception as e:
        st.error(f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}")

# ç»Ÿè®¡ä¿¡æ¯é¡µé¢
elif page == "ç»Ÿè®¡ä¿¡æ¯":
    st.subheader("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
    
    try:
        stats = processor.data_service.get_statistics()
        
        # å…³é”®æŒ‡æ ‡
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ€»è®°å½•æ•°", stats["total_records"])
        with col2:
            st.metric("æ— è´§äº§å“æ•°", stats["out_of_stock_count"])
        with col3:
            st.metric("è§¦å‘é€šçŸ¥æ•°", stats["notified_count"])
        with col4:
            st.metric("ä»Šæ—¥æ–°å¢", stats["today_count"])
    except Exception as e:
        st.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥ï¼š{str(e)}")
